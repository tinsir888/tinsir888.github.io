<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>计算机视觉 W48 Roundup - Uncovered Areas (新课完结) | min hjemmeside</title><meta name="author" content="tinsir888"><meta name="copyright" content="tinsir888"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Cross-entropy revisited Binary cross-entropy loss J(w)&amp;#x3D;−∑i&amp;#x3D;1n(y(i)log⁡(hw(x(i)))+(1−y(i))log⁡(1−hw(x(i))))&amp;#x3D;−∑i&amp;#x3D;1n∑k&amp;#x3D;011{y(i)&amp;#x3D;k}log⁡(Pr⁡(y(i)&amp;#x3D;k∣x(i)))"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://tinsir888.github.io/posts/48cec433.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:1,unescape:!1,languages:{hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1},copy:{success:"Copy Successful",error:"Copy Error",noSupport:"Browser Not Supported"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"Just now",min:"minutes ago",hour:"hours ago",day:"days ago",month:"months ago"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"Load More"},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"计算机视觉 W48 Roundup - Uncovered Areas (新课完结)",isPost:!0,isHome:!1,isHighlightShrink:!0,isToc:!0,postUpdate:"2024-01-26 11:51:48"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach(e=>{n.setAttribute(e,t[e])}),document.head.appendChild(n)}),e.getCSS=(e,t=!1)=>new Promise((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)}),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="min hjemmeside" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">277</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">74</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">32</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-handshake"></i><span> 接力</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-subway"></i><span> 开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go?travel=on"><i class="fa-fw fas fa-rocket"></i><span> 异次元</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/AUcv.jpg)"><nav id="nav"><span id="blog-info"><a href="/" title="min hjemmeside"><span class="site-name">min hjemmeside</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-regular fa-handshake"></i><span> 接力</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-subway"></i><span> 开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go?travel=on"><i class="fa-fw fas fa-rocket"></i><span> 异次元</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">计算机视觉 W48 Roundup - Uncovered Areas (新课完结)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-26T23:00:00.000Z" title="Created 2023-11-27 00:00:00">2023-11-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-01-26T10:51:48.239Z" title="Updated 2024-01-26 11:51:48">2024-01-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AUDatalogi/">AUDatalogi</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AUDatalogi/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">2.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>12mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="计算机视觉 W48 Roundup - Uncovered Areas (新课完结)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="cross-entropy-revisited"><a class="markdownIt-Anchor" href="#cross-entropy-revisited"></a> Cross-entropy revisited</h1><p>Binary cross-entropy loss</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>h</mi><mi>w</mi></msub><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>h</mi><mi>w</mi></msub><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mn>1</mn></munderover><mn mathvariant="bold">1</mn><mo stretchy="false">{</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>k</mi><mo stretchy="false">}</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>k</mi><mi mathvariant="normal">∣</mi><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">J(w)=-\sum_{i=1}^n(y^{(i)}\log(h_w(x^{(i)}))+(1-y^{(i)})\log(1-h_w(x^{(i)})))\\ =-\sum_{i=1}^n\sum_{k=0}^1\mathbf 1\{y^{(i)}=k\}\log(\Pr(y^{(i)}=k|x^{(i)}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.09618em">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em"></span><span class="mord">−</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:.36687em;vertical-align:0"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.1032260000000003em;vertical-align:-1.302113em"></span><span class="mord">−</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.801113em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathbf">1</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mclose">}</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mop">Pr</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>categorical cross entropy loss is used for multi-class classification. similar</p><p>Where does loss function actually come from?</p><blockquote><p>entropy, cross entropy and KL divergence</p></blockquote><h2 id="entropy"><a class="markdownIt-Anchor" href="#entropy"></a> Entropy</h2><p>information entropy is a measure of the uncertainty associated with a given probability distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Pr(x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">Pr</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>formally defined as the average amount of information you get from one random sample, drawn from a probability distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span></p><p>the concept is due to Claude Shannon and was introduced in 1948</p><p>the goal is to reliably send a message from a sender to a recipient</p><p>messages are composed of bits, but not all bits are useful: some are redundant, some are error etc.</p><p>so when we send a message, we want as much useful information as possible to get through</p><p>In Shannon’s theory, sending one bit of information means to reduce the receiver’s uncertainty by a factor of two.</p><p>幻灯片有一个以天气预报为例解释信息熵的例子</p><p>the probability distribution is:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi mathvariant="double-struck">p</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><msub><mo><mi>log</mi><mo>⁡</mo></mo><mn>2</mn></msub><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(\mathbb p)=-\sum_{i=1}^np_i\log_2(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em"></span><span class="mord">−</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.20696799999999996em"><span style="top:-2.4558600000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24414em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><h2 id="cross-entropy"><a class="markdownIt-Anchor" href="#cross-entropy"></a> Cross-entropy</h2><p>the cross entropy between two probability distributions <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span></span></span></span> over the same underlying set of events measures <strong>the average number of bits needed to identify an event drawn from the set</strong> if a coding scheme used for the set is optimized for an estimated probability distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span></span></span></span>, rather than the true distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span>.</p><p>幻灯片有一个以天气预报为例解释交叉熵的例子</p><p>note that if the predicted probabilities equal the true probabilities, then the cross-entropy is just the entropy.</p><p>but if the two distribution differ, the cross-entropy will be larger than the entropy by some number of bits.</p><p>交叉熵实际上就是衡量两个我预测的概率分布和真实的概率分布差距的大小。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi mathvariant="double-struck">p</mi><mo separator="true">,</mo><mi mathvariant="double-struck">q</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><msub><mo><mi>log</mi><mo>⁡</mo></mo><mn>2</mn></msub><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(\mathbb p,\mathbb q)=-\sum_{i=1}^np_i\log_2(q_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em"></span><span class="mord">−</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.20696799999999996em"><span style="top:-2.4558600000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24414em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>: true underlying distribution</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>: predicted distribution</p><h2 id="effect-of-kl-loss-term-in-vaes"><a class="markdownIt-Anchor" href="#effect-of-kl-loss-term-in-vaes"></a> Effect of KL loss term in VAEs</h2><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="double-struck">p</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="double-struck">q</mi><mo stretchy="false">)</mo><mo>=</mo><mi>H</mi><mo stretchy="false">(</mo><mi mathvariant="double-struck">p</mi><mo separator="true">,</mo><mi mathvariant="double-struck">q</mi><mo stretchy="false">)</mo><mo>−</mo><mi>H</mi><mo stretchy="false">(</mo><mi mathvariant="double-struck">p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{KL}(\mathbb p||\mathbb q)=H(\mathbb p,\mathbb q)-H(\mathbb p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span></span></p><p>KL 散度就是交叉熵减去信息熵。</p><p>the amount by which the cross-entropy exceeds the entropy, is called the relative entropy, or Kullback-Leibler Divergence.</p><p>the KL loss term pushes the latent representation towards a standard normal distribution, i.e., the i-th element is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>∼</mo><mi>N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z_i\sim N(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>.</p><h2 id="application-in-softmax-regression"><a class="markdownIt-Anchor" href="#application-in-softmax-regression"></a> Application in softmax regression</h2><p>we need a loss function that compares the predicted probabilities with the true probabilities.</p><p>use cross-entropy to compare them.</p><h1 id="wrap-up-on-gans"><a class="markdownIt-Anchor" href="#wrap-up-on-gans"></a> Wrap-up on GANs</h1><p>generator network: try to fool the discriminator by generating real-looking images</p><p>discriminator network: try to distinguish between real and fake images.</p><p>DCGAN = GAN + Deep Convolution</p><p>Conditional GAN</p><ul><li>the original GAN generates data from random noise but has no knowledge about class labels.</li><li>CGAN aims to solve this issue by telling the generator to generate images of only one particular class, like a cat or a dog.</li><li>specifically, CGAN concatenates a one-hot vector <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">y</mi></mrow><annotation encoding="application/x-tex">\mathbb y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span> to the random noise vector <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">z</mi></mrow><annotation encoding="application/x-tex">\mathbb z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.04398em">z</span></span></span></span> to result in an architecture.</li></ul><p>Pix2Pix</p><p>CycleGAN</p><p>ProGAN - aka progressive growing of GAN - purpose is to generate high resolution images</p><p>BigGAN</p><h2 id="common-problems-in-training-gans"><a class="markdownIt-Anchor" href="#common-problems-in-training-gans"></a> Common problems in training GANs</h2><p>non-convergence</p><p>mode collapse</p><p>diminished gradient</p><p>unbalanced between G and D</p><p>highly sensitive to hyper-parameter selections.</p><h2 id="stabilizing-gan-training"><a class="markdownIt-Anchor" href="#stabilizing-gan-training"></a> Stabilizing GAN training</h2><p>WGAN proposes a new loss function that has some nice properties that lead to a higher quality of the gradients to train the generator.</p><h1 id="diffusion-models"><a class="markdownIt-Anchor" href="#diffusion-models"></a> Diffusion Models</h1><h2 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h2><p>GAN and VAE convert noise vector to image in a single forward pass.</p><p>fast but hard to learn a model</p><p>diffusion model generate image from noise by iterative denoising</p><p>slow but much easier to learn</p><h2 id="recall-denoising-autoencoder"><a class="markdownIt-Anchor" href="#recall-denoising-autoencoder"></a> Recall Denoising Autoencoder</h2><p>train an autoencoder to undo the effect of a corruption process stochastically applied to the input</p><p>the underlying idea is very simple: add random noise to the input and teach the auto encoder to remove the noise.</p><h2 id="basic-idea-2-process"><a class="markdownIt-Anchor" href="#basic-idea-2-process"></a> Basic idea - 2 process</h2><ol><li><p>pre-defined forward diffusion: gradually adds noise to the input</p><p>一共 t 步，每一步都加一点高斯噪声。有专门的公式去控制。</p><p>diffusion kernel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator="true">;</mo><msqrt><msub><mi>α</mi><mi>t</mi></msub></msqrt><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(X_t|X_0)=\mathcal N(x_t;\sqrt{\alpha_t}x_0,(1-\alpha_t)I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0647199999999999em;vertical-align:-.31472em"></span><span class="mord mathcal" style="margin-right:.14736em">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.72528em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.0037em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.68528em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.31472em"><span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.0037em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mclose">)</span></span></span></span></p></li><li><p>reverse denoising: neural network is trained to gradually denoise the data, starting from pure noise.</p><p>neural network: approximate these conditional probabilities in order to run the reverse diffusion process.</p></li></ol><p>（此处省略了一些有关 diffusion model 的细节）</p><h2 id="conditional-diffusion-models"><a class="markdownIt-Anchor" href="#conditional-diffusion-models"></a> Conditional diffusion models</h2><p>an additional input <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span> (class label or a text sequence) is available and we try to model the conditional distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x|y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mclose">)</span></span></span></span> instead.</p><p>in practice, the denoising model is also conditioned on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span> in addition to the image from the previous timestep <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>.</p><p>this allows us to generate data given the conditioning signal.</p><h2 id="classifier-guided-diffusion-model"><a class="markdownIt-Anchor" href="#classifier-guided-diffusion-model"></a> Classifier-guided diffusion model</h2><p>main idea: train an extra classifier and mix its gradient with the diffusion model during sampling</p><h2 id="clip-guided-diffusion-model"><a class="markdownIt-Anchor" href="#clip-guided-diffusion-model"></a> CLIP-guided diffusion model</h2><p>given an image <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">x</span></span></span></span> and prompt <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span>, a CLIP model computes the alignment <em>cosine similarity</em> of x and y, which indicates how similar the image and the prompt are.</p><p>to use this signal for guidance, we assume that the CLIP similarity score is a good estimation of the function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>.</p><p>the gradient of this score w.r.t. the noised image, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> at timestep <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> is used as the guidance gardient.</p><p>note that this requires the CLIP model to compute score for noised-images at intermediate timestep, hence a noised CLIP model is trained for guidance.</p><h2 id="dall-e-and-stable-diffusion"><a class="markdownIt-Anchor" href="#dall-e-and-stable-diffusion"></a> DALL-E and Stable Diffusion</h2><p>encoding from CLIP as the target encoding</p><p>用类似于 inverting CNN 的东西，找到相似 latent feature 表达的图。</p><p>DALL-E 2: conditioning on CLIP-embeddings</p><ul><li>helps capture multimodal representations</li><li>the bi-partite latent enables several text-controlled image manipulation tasks</li></ul><p>Stable Diffusion</p><ul><li>text embedding: describes the content in words</li><li>random noise: random initialization, unique generated image every time</li></ul><h2 id="latent-diffusion-models"><a class="markdownIt-Anchor" href="#latent-diffusion-models"></a> Latent Diffusion Models</h2><p>LDM applies the diffusion processes in the latent space instead of pixel space while incorporating semantic feed back from a transformer.</p><p>not only memory efficient, they also produce diverse, highly detailed images which preserve the semantic structure of the data.</p><h2 id="conditioned-latent-diffusion"><a class="markdownIt-Anchor" href="#conditioned-latent-diffusion"></a> Conditioned Latent Diffusion</h2><p>the image generation task is conditioned on a prior</p><p>denoising U-Net autoencoder with cross-attention (Q, K, V)</p><h1 id="attention-revisited"><a class="markdownIt-Anchor" href="#attention-revisited"></a> Attention revisited</h1><p>Self-attention in CNNs</p><p>Self-attention in GANs aka SAGAN</p><ul><li>add the attention weights back onto input layer itself with a weight of gamma, a learnable parameter initializing at 0. It means that the self-attention module does not do anything initially.</li></ul><p>attention U-Net</p><ul><li>during unsampling in the decoder, spatial information recreated is imprecise. to counteract this problem, the U-Net uses skip-connections that utilize spatial information from the down-sampling in the encoder. Attention gates implemented at the skip connection will actively suppress activations in irrelevant regions, reducing the number of redundant features brought across.</li></ul><p>CBAM aka convolutional block attention module</p><ul><li>attention module for CNN</li><li>given an intermediate feature map, the module sequentially infers attention maps along two separate dimensions, channels and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement.</li></ul><h1 id="self-supervised-learning"><a class="markdownIt-Anchor" href="#self-supervised-learning"></a> Self-supervised learning</h1><p>goal: learn from data without manual label annotation</p><p>self-supervised learning methods solve pretext tasks that produce good features for downstream tasks</p><p>learn with supervised learning objectives e.g. classification, regression</p><p>labels of these pretext tasks are generated automatically.</p><h2 id="how-to-evaluate-an-ssl-method"><a class="markdownIt-Anchor" href="#how-to-evaluate-an-ssl-method"></a> How to evaluate an SSL method?</h2><p>we usually don’t care about the performance of the self-supervised learning task e.g., we don’t care if the model learns to predict image rotation perfectly.</p><p>evaluate the learned feature encoder on downstream target tasks.</p><h3 id="pretext-task-predict-rotations"><a class="markdownIt-Anchor" href="#pretext-task-predict-rotations"></a> pretext task: predict rotations</h3><p>self-supervised learning by rotating the entire input image</p><p>the model learns to predict which rotation is applied</p><h3 id="evaluation-on-semi-supervised-learning"><a class="markdownIt-Anchor" href="#evaluation-on-semi-supervised-learning"></a> evaluation on semi-supervised learning</h3><p>self-supervised learning on CIFAR10</p><p>freeze conv1 + conv2 learn conv3 + linear layers with subset of labeled CIFAR10 data.</p><h3 id="other-pretext-tasks"><a class="markdownIt-Anchor" href="#other-pretext-tasks"></a> other pretext tasks</h3><ul><li>solving jigsaw puzzles 拼图游戏</li><li>predict relative path locations</li><li>predict missing pixels</li><li>image coloring</li></ul><h3 id="summary-pretext-tasks-from-transformations"><a class="markdownIt-Anchor" href="#summary-pretext-tasks-from-transformations"></a> Summary: pretext tasks from transformations</h3><p>pretext tasks focus on visual common sense</p><p>the model are forced to learn good features about natural images e.g. semantic representation of an object category, in order to solve the pretext tasks</p><p>we don’t care about the performance of these pretext tasks, but rather how useful the learned features are for downstream tasks.</p><p>problems:</p><ul><li>coming up with individual pretext tasks is tedious</li><li>the learned representations may not be general</li></ul><h2 id="a-more-general-pretext-task"><a class="markdownIt-Anchor" href="#a-more-general-pretext-task"></a> A more general pretext task</h2><p>contrastive representation learning</p><ul><li>given a chosen score function, we aim to learn an encoder network <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span></span></span></span> that yields high score for positive pairs and low score for negative pairs</li></ul><p>Masked Autoencoder</p><p>（当时在华为实习的时候我就搞的这玩意……）</p><p>CLIP</p><h1 id="siamese-network"><a class="markdownIt-Anchor" href="#siamese-network"></a> Siamese network</h1><h2 id="motivation-2"><a class="markdownIt-Anchor" href="#motivation-2"></a> motivation</h2><p>assume that we want to build a face recognition system for a small organization with only 10 employees</p><p>using a traditional classification approach, we might come up with a system like: 输入图片 - 分类器 - 输出是每个种类对应概率值。</p><p>problem</p><ol><li>to train such a system, we first require a lot of different images of each of the 10 person in the organization which might not be feasible.</li><li>what if a new person joins or leaves the organization? you need to take the pain of collecting data again and re-train the entire model again.</li></ol><p>Siamese network helps to solve both of above issues, instead of directly classifying an input image to one of the 10 people in the organization, this network instead takes an extra reference image of the person as input and produces a similarity score denoting the chances that the two input images belong to the same person.</p><p>notice that this network is not learning to classify an image directly to any of the output classes, rather, it is learning a similarity function, which takes two images as input and expresses how similar they are.</p><p>in practice:</p><ul><li>to train this network, don’t require too many instances of a class and only few are enough to build a good model.</li><li>but the biggest advantage is that, let’s say in case of face recognition, we have a new employee who has joined the organization. new in order for the network to detect his/her face, we only require a single image of his/her face which will be stored in the database. using this as the reference image, the network will calculate the similarity for any new instance presented to it. Thus, we say that network predicts the score in <strong>one shot</strong>.</li></ul><h2 id="architecture"><a class="markdownIt-Anchor" href="#architecture"></a> Architecture</h2><p>将检测图和对比图输入同一个 ConvNet 中，分别得到两个图的 encoding，再将这两个 encoding 拿到判别其中，检查相似度，在经过 sigmoid 函数激活后得到相似度打分。</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://tinsir888.github.io">tinsir888</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://tinsir888.github.io/posts/48cec433.html">https://tinsir888.github.io/posts/48cec433.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></div><div class="post_share"><div class="social-share" data-image="/img/AUcv.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/b3ed4a5b.html" title="计算几何 W48 Robot Motion Planning and Visibility (新课完结)"><img class="cover" src="/img/AUcg.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">计算几何 W48 Robot Motion Planning and Visibility (新课完结)</div></div></a></div><div class="next-post pull-right"><a href="/posts/fca6d754.html" title="算法博弈论 W48 Potential games and price of stability (新课完结)"><img class="cover" src="/img/AUagt.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">算法博弈论 W48 Potential games and price of stability (新课完结)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/posts/e7117333.html" title="计算机视觉 W47 Sequence models (natural language processing)"><img class="cover" src="/img/AUcv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-20</div><div class="title">计算机视觉 W47 Sequence models (natural language processing)</div></div></a></div><div><a href="/posts/61b1055e.html" title="计算机视觉 W46 Visualizing and understanding CNNs"><img class="cover" src="/img/AUcv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-13</div><div class="title">计算机视觉 W46 Visualizing and understanding CNNs</div></div></a></div><div><a href="/posts/56ab7808.html" title="计算机视觉 W45 Generative models"><img class="cover" src="/img/AUcv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-06</div><div class="title">计算机视觉 W45 Generative models</div></div></a></div><div><a href="/posts/4802d8c1.html" title="计算机视觉 W44 Object detection and segmentation"><img class="cover" src="/img/AUcv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-30</div><div class="title">计算机视觉 W44 Object detection and segmentation</div></div></a></div><div><a href="/posts/7a6ff316.html" title="计算机视觉 W43 CNN architectures"><img class="cover" src="/img/AUcv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-23</div><div class="title">计算机视觉 W43 CNN architectures</div></div></a></div><div><a href="/posts/4d54f26b.html" title="计算机视觉 W41 Training ConvNet (2)"><img class="cover" src="/img/AUcv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-09</div><div class="title">计算机视觉 W41 Training ConvNet (2)</div></div></a></div></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">tinsir888</div><div class="author-info__description">Elysium :-)</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">277</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">74</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">32</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://www.github.com/tinsir888"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/tinsir888" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:smalltalk.odin@protonmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Ηλύσια Πεδία ;-)</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cross-entropy-revisited"><span class="toc-number">1.</span> <span class="toc-text">Cross-entropy revisited</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#entropy"><span class="toc-number">1.1.</span> <span class="toc-text">Entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cross-entropy"><span class="toc-number">1.2.</span> <span class="toc-text">Cross-entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#effect-of-kl-loss-term-in-vaes"><span class="toc-number">1.3.</span> <span class="toc-text">Effect of KL loss term in VAEs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#application-in-softmax-regression"><span class="toc-number">1.4.</span> <span class="toc-text">Application in softmax regression</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#wrap-up-on-gans"><span class="toc-number">2.</span> <span class="toc-text">Wrap-up on GANs</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#common-problems-in-training-gans"><span class="toc-number">2.1.</span> <span class="toc-text">Common problems in training GANs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stabilizing-gan-training"><span class="toc-number">2.2.</span> <span class="toc-text">Stabilizing GAN training</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#diffusion-models"><span class="toc-number">3.</span> <span class="toc-text">Diffusion Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#motivation"><span class="toc-number">3.1.</span> <span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#recall-denoising-autoencoder"><span class="toc-number">3.2.</span> <span class="toc-text">Recall Denoising Autoencoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#basic-idea-2-process"><span class="toc-number">3.3.</span> <span class="toc-text">Basic idea - 2 process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conditional-diffusion-models"><span class="toc-number">3.4.</span> <span class="toc-text">Conditional diffusion models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#classifier-guided-diffusion-model"><span class="toc-number">3.5.</span> <span class="toc-text">Classifier-guided diffusion model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#clip-guided-diffusion-model"><span class="toc-number">3.6.</span> <span class="toc-text">CLIP-guided diffusion model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dall-e-and-stable-diffusion"><span class="toc-number">3.7.</span> <span class="toc-text">DALL-E and Stable Diffusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#latent-diffusion-models"><span class="toc-number">3.8.</span> <span class="toc-text">Latent Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conditioned-latent-diffusion"><span class="toc-number">3.9.</span> <span class="toc-text">Conditioned Latent Diffusion</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#attention-revisited"><span class="toc-number">4.</span> <span class="toc-text">Attention revisited</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#self-supervised-learning"><span class="toc-number">5.</span> <span class="toc-text">Self-supervised learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#how-to-evaluate-an-ssl-method"><span class="toc-number">5.1.</span> <span class="toc-text">How to evaluate an SSL method?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pretext-task-predict-rotations"><span class="toc-number">5.1.1.</span> <span class="toc-text">pretext task: predict rotations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#evaluation-on-semi-supervised-learning"><span class="toc-number">5.1.2.</span> <span class="toc-text">evaluation on semi-supervised learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#other-pretext-tasks"><span class="toc-number">5.1.3.</span> <span class="toc-text">other pretext tasks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#summary-pretext-tasks-from-transformations"><span class="toc-number">5.1.4.</span> <span class="toc-text">Summary: pretext tasks from transformations</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a-more-general-pretext-task"><span class="toc-number">5.2.</span> <span class="toc-text">A more general pretext task</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#siamese-network"><span class="toc-number">6.</span> <span class="toc-text">Siamese network</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#motivation-2"><span class="toc-number">6.1.</span> <span class="toc-text">motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#architecture"><span class="toc-number">6.2.</span> <span class="toc-text">Architecture</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/970b0da7.html" title="Efficient ReliK 2 Possible Parallelization Idea"><img src="/img/AUrelik.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Efficient ReliK 2 Possible Parallelization Idea"></a><div class="content"><a class="title" href="/posts/970b0da7.html" title="Efficient ReliK 2 Possible Parallelization Idea">Efficient ReliK 2 Possible Parallelization Idea</a><time datetime="2024-09-16T22:00:00.000Z" title="Created 2024-09-17 00:00:00">2024-09-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/d1c3d6da.html" title="丹麦语 DU 3.3 4 Fællesskaber - Højskoler"><img src="/img/dansk-du33.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="丹麦语 DU 3.3 4 Fællesskaber - Højskoler"></a><div class="content"><a class="title" href="/posts/d1c3d6da.html" title="丹麦语 DU 3.3 4 Fællesskaber - Højskoler">丹麦语 DU 3.3 4 Fællesskaber - Højskoler</a><time datetime="2024-09-16T22:00:00.000Z" title="Created 2024-09-17 00:00:00">2024-09-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3bdc648b.html" title="Efficient ReliK 1 Paper Reading"><img src="/img/AUrelik.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Efficient ReliK 1 Paper Reading"></a><div class="content"><a class="title" href="/posts/3bdc648b.html" title="Efficient ReliK 1 Paper Reading">Efficient ReliK 1 Paper Reading</a><time datetime="2024-09-14T22:00:00.000Z" title="Created 2024-09-15 00:00:00">2024-09-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/5782b241.html" title="算法和计算复杂度 8 Branching Programs and Barrington’s Theorem"><img src="/img/AUtacc.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="算法和计算复杂度 8 Branching Programs and Barrington’s Theorem"></a><div class="content"><a class="title" href="/posts/5782b241.html" title="算法和计算复杂度 8 Branching Programs and Barrington’s Theorem">算法和计算复杂度 8 Branching Programs and Barrington’s Theorem</a><time datetime="2024-09-13T22:00:00.000Z" title="Created 2024-09-14 00:00:00">2024-09-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/7e9f3293.html" title="Fair AI/ML 1 Core-Stability Federated Learning"><img src="/img/AUFairAI.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Fair AI/ML 1 Core-Stability Federated Learning"></a><div class="content"><a class="title" href="/posts/7e9f3293.html" title="Fair AI/ML 1 Core-Stability Federated Learning">Fair AI/ML 1 Core-Stability Federated Learning</a><time datetime="2024-09-12T22:00:00.000Z" title="Created 2024-09-13 00:00:00">2024-09-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/AUcv.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By tinsir888</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><span class="footer-separator">|</span><span> </span><a href="https://icp.gov.moe/?keyword=20248537" target="_blank"><img src="https://icp.gov.moe/images/ico64.png" alt="icon" width="16" height="16" style="vertical-align:middle;margin-right:5px">萌ICP备20248537号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>document.querySelectorAll("#article-container span.katex-display").forEach(a=>{btf.wrap(a,"div",{class:"katex-wrap"})})</script><script>(()=>{const e=document.querySelectorAll("#article-container .mermaid-wrap");if(0===e.length)return;const t=()=>{window.loadMermaid=!0;const t="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";Array.from(e).forEach((e,n)=>{const d=e.firstElementChild,r="mermaid-"+n,a="%%{init:{ 'theme':'"+t+"'}}%%\n"+d.textContent,i=mermaid.render(r,a);var m;"string"==typeof i?(m=i,d.insertAdjacentHTML("afterend",m)):i.then(({svg:e})=>{d.insertAdjacentHTML("afterend",e)})})},n=()=>{window.loadMermaid?t():getScript("https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js").then(t)};btf.addGlobalFn("themeChange",t,"mermaid"),window.pjax?n():document.addEventListener("DOMContentLoaded",n)})()</script><script>(()=>{const t=()=>{new Gitalk(Object.assign({clientID:"e1723135269b287b0966",clientSecret:"b3eb09deb82a253cc57efd054834f5dac3354cb8",repo:"tinsir888.github.io-gittalk",owner:"tinsir888",admin:["tinsir888"],id:"fdfa7845af2588cf1327f0503d557092",updateCountCallback:n},null)).render("gitalk-container")},i=async()=>{"function"==typeof Gitalk||(await getCSS("https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"),await getScript("https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js")),t()},n=t=>{const i=document.querySelector("#post-meta .gitalk-comment-count");i&&(i.textContent=t)};i()})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>